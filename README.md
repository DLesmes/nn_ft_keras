# nn_ft_keras
ðŸ“– Notes, notebooks, and resources from the course ðŸ‘¾ Neuronal networks ft python and keras

* [Course_notes](https://github.com/ichcanziho/Deep_Learnining_Platzi/blob/master/1%20Curso%20de%20fundamentos%20de%20redes%20neuronales/README.MD)
* [Course_notes 2.0](https://erickordazr.notion.site/20-Funciones-de-activaci-n-6ad24dcb27414fc4b04bcac4d5a94791)
* [Course Slides](https://github.com/DLesmes/nn_ft_keras/blob/main/slides_redes_neuronales_89023833-92a7-4f38-aa2a-776b5d940924.pdf)

# Recommended lectures

* Blogs
  * [Microscope](https://microscope.openai.com/models)
  * [What is MNIST? And why is it important?](https://selectstar-ai.medium.com/what-is-mnist-and-why-is-it-important-e9a269edbad5)
  * [Activation Functions in Neural Networks [12 Types & Use Cases]](https://www.v7labs.com/blog/neural-networks-activation-functions)
  * [Machine Learning for Beginners: An Introduction to Neural Networks](https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9)
  * [Todo lo que Necesitas Saber sobre el Descenso del Gradiente Aplicado a Redes Neuronales](https://medium.com/metadatos/todo-lo-que-necesitas-saber-sobre-el-descenso-del-gradiente-aplicado-a-redes-neuronales-19bdbb706a78)
  * [An Interactive Tutorial on Numerical Optimization](https://www.benfrederickson.com/numerical-optimization/)
  * [Why Momentum Really Works](https://distill.pub/2017/momentum/)
  * [Stochastic gradient descent ](https://realpython.com/gradient-descent-algorithm-python/#:~:text=Stochastic%20gradient%20descent%20is%20an,an%20inexact%20but%20powerful%20technique.)
  * [Implement Gradient Descent in Python](https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1)
  * [[Collection] 10 Best NumPy Cheat Sheets Every Python Coder Must Own](https://blog.finxter.com/collection-10-best-numpy-cheat-sheets-every-python-coder-must-own/)
  * [keras losses](https://keras.io/api/losses/)
* Web apps | demos
  * [Demo CNN handwrite digits](https://adamharley.com/nn_vis/cnn/3d.html)
  * [wolframalpha](https://www.wolframalpha.com/)
  * [Compute Derivate](https://www.desmos.com/calculator/l0puzw0zvm)
  * [Neuronal Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.67753&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)
* Videos
  * [CPU vs GPU vs TPU vs DPU vs QPU](https://www.youtube.com/watch?v=r5NQecwZs1A)
  * [1.- Redes Neuronales: FÃ¡cil y desde cero](https://www.youtube.com/watch?v=jaEIv_E29sk&list=PLAnA8FVrBl8AWkZmbswwWiF8a_52dQ3JQ)
  * [Jugando con Redes Neuronales - Parte 2.5 | DotCSV](https://www.youtube.com/watch?v=FVozZVUNOOA&t=203s)
  * [Â¿QuÃ© es una Red Neuronal? Parte 1 : La Neurona | DotCSV](https://www.youtube.com/watch?v=MRIv2IwFTPg&list=PL-Ogd76BhmcB9OjPucsnc2-piEE96jJDQ)
  * [Â¿QuÃ© es una Red Neuronal? Parte 2 : La Red | DotCSV](https://www.youtube.com/watch?v=uwbHOpp9xkc&list=PL-Ogd76BhmcB9OjPucsnc2-piEE96jJDQ&index=3)
  * [Â¿QuÃ© es una Red Neuronal? Parte 3 : Backpropagation | DotCSV](https://www.youtube.com/watch?v=eNIqz_noix8)
  * [Â¿QuÃ© es una Red Neuronal? Parte 3.5 : Las MatemÃ¡ticas de Backpropagation | DotCSV](https://www.youtube.com/watch?v=M5QHwkkHgAA)
  * [Â¿QuÃ© es el Descenso del Gradiente? Algoritmo de Inteligencia Artificial | DotCSV](https://www.youtube.com/watch?v=A6FiCDoz8_4)
  * [Learn TensorFlow and Deep Learning fundamentals with Python (code-first introduction) Part 2/2](https://www.youtube.com/watch?v=ZUKz4125WNI)
  * [El cerebro de Stilwell](https://www.youtube.com/watch?v=rA5qnZUXcqo)
  * [Descenso de gradiente, cÃ³mo aprenden las redes neuronales | CapÃ­tulo 2, Aprendizaje profundo](https://www.youtube.com/watch?v=IHZwWFHWa-w)
  * [CC6204 Deep Learning, Clase 05-2020: IntroducciÃ³n a Backpropagation](https://www.youtube.com/watch?v=1EUAoM1EhM0&list=PLBjZ-ginWc1e0_Dp4heHglsjJmacV_F20&index=7)
  * [27. Backpropagation: Find Partial Derivatives](https://www.youtube.com/watch?v=lZrIPRnoGQQ)
  * [5.1.2 Backpropagation Algorithm by Andrew Ng](https://www.youtube.com/watch?v=mO7BpWmzT78)
* Dataset
  * [MNIST digits classification dataset](https://keras.io/api/datasets/mnist/)
  * [keras - imdb](https://keras.io/api/datasets/imdb/)
* Papers
  * [On the importance of initialization and momentum in deep learning](https://web.archive.org/web/20150922064556/https://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf)
  *   
